{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1Ô∏è‚É£ Load the Dataset\n",
        "- Load the CSV file into a pandas DataFrame.\n",
        "- Display the first 5 rows of the dataset.\n",
        "\n",
        "2Ô∏è‚É£ Feature Selection\n",
        "- Extract the following columns:\n",
        "- pickup_latitude\n",
        "- pickup_longitude\n",
        "- Store them in a variable named X.\n",
        "\n",
        "3Ô∏è‚É£ Data Preprocessing\n",
        "- Apply StandardScaler to scale the selected - features.\n",
        "- Store the scaled data in X_scaled.\n",
        "\n",
        "4Ô∏è‚É£ DBSCAN Model ‚Äì Experiment 1\n",
        "- Apply DBSCAN with:\n",
        "- eps = 0.2\n",
        "- min_samples = 5\n",
        "- Store cluster labels in labels_1.\n",
        "\n",
        "5Ô∏è‚É£ DBSCAN Model ‚Äì Experiment 2\n",
        "- Apply DBSCAN with:\n",
        "- eps = 0.3\n",
        "- min_samples = 5\n",
        "- Store cluster labels in labels_2.\n",
        "\n",
        "6Ô∏è‚É£ DBSCAN Model ‚Äì Experiment 3\n",
        "- Apply DBSCAN with:\n",
        "- eps = 0.5\n",
        "- min_samples = 5\n",
        "- Store cluster labels in labels_3.\n",
        "\n",
        "7Ô∏è‚É£ Cluster Evaluation\n",
        "- For each experiment:\n",
        "- Print:\n",
        "    Number of clusters (excluding noise)\n",
        "    Number of noise points\n",
        "    Noise ratio\n",
        "\n",
        "8Ô∏è‚É£ Silhouette Score Calculation\n",
        "- Remove noise points (-1) from each experiment.\n",
        "- Calculate and print the Silhouette Score for:\n",
        "    - Experiment 1\n",
        "    - Experiment 2\n",
        "    - Experiment 3\n",
        "- If silhouette score is not applicable, print \"Not Applicable\".\n",
        "\n",
        "9Ô∏è‚É£ Visualization\n",
        "- For each experiment:\n",
        "    - Plot pickup locations using a scatter plot.\n",
        "    - Color points based on cluster labels.\n",
        "    - Highlight noise points using a separate color.\n",
        "    \n",
        "üîü Best Model Selection\n",
        "- Based on:\n",
        "    - Number of clusters\n",
        "    - Noise ratio\n",
        "    - Silhouette score\n",
        "- Print:\n",
        "    Best eps value = ___"
      ],
      "metadata": {
        "id": "zu5VsSDv_pHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n"
      ],
      "metadata": {
        "id": "5AMLoX8UGQxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TUgEAgKytug"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file path inside Google Drive\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/DataSets/NewYorkCityTaxiTripDuration.csv\"\n",
        "\n",
        "df=pd.read_csv(file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "apL60L_z3D4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2Ô∏è‚É£ Feature Selection - Extract pickup_latitude & pickup_longitude\n",
        "\n",
        "X = df[['pickup_latitude', 'pickup_longitude']].copy()\n",
        "X.dropna(inplace=True)\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "id": "n3SRFlMbGb_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3Ô∏è‚É£ Data Preprocessing - Apply StandardScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_scaled[:5]\n"
      ],
      "metadata": {
        "id": "s0CDknSWG77W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4Ô∏è‚É£ DBSCAN Model ‚Äì Experiment 1 (eps=0.2, min_samples=5)\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "db1 = DBSCAN(eps=0.2, min_samples=5)\n",
        "labels_1 = db1.fit_predict(X_scaled)\n",
        "\n",
        "labels_1[:10]\n"
      ],
      "metadata": {
        "id": "3N_t15t0G9AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5Ô∏è‚É£ DBSCAN Model ‚Äì Experiment 2 (eps=0.3, min_samples=5)\n",
        "\n",
        "db2 = DBSCAN(eps=0.3, min_samples=5)\n",
        "labels_2 = db2.fit_predict(X_scaled)\n",
        "\n",
        "labels_2[:10]\n"
      ],
      "metadata": {
        "id": "PjblVr4eG_wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6Ô∏è‚É£ DBSCAN Model ‚Äì Experiment 3 (eps=0.5, min_samples=5)\n",
        "\n",
        "db3 = DBSCAN(eps=0.5, min_samples=5)\n",
        "labels_3 = db3.fit_predict(X_scaled)\n",
        "\n",
        "labels_3[:10]\n"
      ],
      "metadata": {
        "id": "dWZc8R8yHDfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7Ô∏è‚É£ Cluster Evaluation - Print clusters, noise count, noise ratio\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(labels, name):\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise = list(labels).count(-1)\n",
        "    noise_ratio = n_noise / len(labels)\n",
        "\n",
        "    print(f\"{name}\")\n",
        "    print(\"Clusters:\", n_clusters)\n",
        "    print(\"Noise Points:\", n_noise)\n",
        "    print(\"Noise Ratio:\", round(noise_ratio, 4))\n",
        "    print(\"-\"*40)\n",
        "\n",
        "evaluate(labels_1, \"Experiment 1 (eps=0.2)\")\n",
        "evaluate(labels_2, \"Experiment 2 (eps=0.3)\")\n",
        "evaluate(labels_3, \"Experiment 3 (eps=0.5)\")\n"
      ],
      "metadata": {
        "id": "DLyaCXlpHEe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8Ô∏è‚É£ Silhouette Score - Remove noise and calculate score\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "def calculate_silhouette(X_scaled, labels, name):\n",
        "    mask = labels != -1\n",
        "\n",
        "    if len(set(labels[mask])) > 1:\n",
        "        score = silhouette_score(X_scaled[mask], labels[mask])\n",
        "        print(f\"{name} Silhouette Score:\", round(score, 4))\n",
        "        return score\n",
        "    else:\n",
        "        print(f\"{name} Silhouette Score: Not Applicable\")\n",
        "        return None\n",
        "\n",
        "score1 = calculate_silhouette(X_scaled, labels_1, \"Experiment 1\")\n",
        "score2 = calculate_silhouette(X_scaled, labels_2, \"Experiment 2\")\n",
        "score3 = calculate_silhouette(X_scaled, labels_3, \"Experiment 3\")\n"
      ],
      "metadata": {
        "id": "1yQrsjKWHEbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9Ô∏è‚É£ Visualization - Scatter plot with cluster colors & noise highlighted\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_clusters(X, labels, title):\n",
        "    plt.figure(figsize=(6,5))\n",
        "\n",
        "    unique_labels = set(labels)\n",
        "    for label in unique_labels:\n",
        "        if label == -1:\n",
        "            color = 'black'\n",
        "            marker = 'x'\n",
        "            label_name = 'Noise'\n",
        "        else:\n",
        "            color = None\n",
        "            marker = 'o'\n",
        "            label_name = f'Cluster {label}'\n",
        "\n",
        "        plt.scatter(\n",
        "            X[labels == label, 0],\n",
        "            X[labels == label, 1],\n",
        "            c=color,\n",
        "            marker=marker,\n",
        "            label=label_name,\n",
        "            s=10\n",
        "        )\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Latitude (scaled)\")\n",
        "    plt.ylabel(\"Longitude (scaled)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_clusters(X_scaled, labels_1, \"Experiment 1 (eps=0.2)\")\n",
        "plot_clusters(X_scaled, labels_2, \"Experiment 2 (eps=0.3)\")\n",
        "plot_clusters(X_scaled, labels_3, \"Experiment 3 (eps=0.5)\")\n"
      ],
      "metadata": {
        "id": "EJEiAsorHJYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîü Best Model Selection - Based on clusters, noise ratio & silhouette score\n",
        "\n",
        "results = {\n",
        "    0.2: score1,\n",
        "    0.3: score2,\n",
        "    0.5: score3\n",
        "}\n",
        "\n",
        "# Remove None values\n",
        "valid_scores = {k: v for k, v in results.items() if v is not None}\n",
        "\n",
        "if valid_scores:\n",
        "    best_eps = max(valid_scores, key=valid_scores.get)\n",
        "    print(\"Best eps value =\", best_eps)\n",
        "else:\n",
        "    print(\"Best eps value = Not Applicable\")\n"
      ],
      "metadata": {
        "id": "os4-P8CDHRli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}